package azdblab.plugins.scenario;

import java.io.File;

import java.io.FileInputStream;
import java.io.FileOutputStream;
import java.text.SimpleDateFormat;
import java.util.Date;
import java.util.HashMap;
import java.util.TreeSet;
import java.util.Iterator;
import java.util.Vector;
import org.w3c.dom.Element;
import azdblab.Constants;
import azdblab.executable.Main;
import azdblab.labNotebook.PlanNode;
import azdblab.labNotebook.QueryRunStat;
import azdblab.labNotebook.RepeatableRandom;
import azdblab.labNotebook.dataModel.Query; 
//import azdblab.labNotebook.dataModel.Run;
import azdblab.model.analyzer.QueryRun;
import azdblab.model.experiment.ExperimentRun;
import azdblab.model.experiment.Table;
import azdblab.model.experiment.XMLHelper;

/**
 * <p>This is an experiment scenario that examines query plan generation 
 * by varying the cardinality of the variable tables. The approach for altering
 * the cardinality is specific to each sub-class.</p>
 * Four steps, namely stepA, stepB, stepC, and stepD are provided for
 * implement specific experiment execution steps. Note that in this class, all
 * these steps only provide the default actions, which simply returns as soon as
 * the method is called. It is the responsibilty of each subclass to override
 * these methods to specialize this experiment scenario.
 * <p>Generally, the set of fixed experiment tables will be created and
 * populated by calling the <code>populateFixedTable</code> method. The 
 * variable tables should be handled by <code>stepA</code>.
 * The actual experiment will then loop on the phases which will each invoke
 * the <code>analyzeQuery</code> method.</p>
 * <p>In each <code>analyzeQuery</code>, an individual query is studied. At
 * first, the scenario need to examine the query execution at the "actual"
 * cardinality, thus the scenario call <code>stepB</code> to measure the
 * execution time then call <code>recordQueryRun</code> to store the details of
 * the "optimal" plan into the lab notebook. Since our main goal is to study
 * the query plans at various cardinalities, the scenario first provide a
 * sequence of pre-computed candidate cardinality values by calling
 * <code>generateCandidateCardinalities</code>.
 * The scenario then iterates over these values starting from the maximum and
 * then decrease with calls to <code>stepC</code>, which changes the table
 * cardinality as requested, either physically or virtually, according to the
 * implementations of sub-scenarios. Following <code>stepC</code>, the scenario
 * calls <code>stepD</code> to measure the plan execution time and
 * <code>recordQueryRun</code> to store the detail of the plan execution.</p>
 * <p><code>stepE</code>, <code>stepF</code> and <code>stepG</code> provide
 * extra functionalities for performing experiments. Subclasses should override
 * them if necessary.
 * </p>
 * <p>The scenario provides the <code>timeQueryExecution</code> method in the
 * experiment since some of the experiment scenarios will study the performance
 * of plans. This method may be called by <code>stepB</code> and
 * <code>stepD</code>. In the case the timing information is not needed in the
 * experiment, subclasses should use the default <code>stepB</code> and
 * <code>stepD</code> implementations which do no timing.</p>
 * @author ruizhang
 */
public abstract class VaryCardinalityScenario extends Scenario {
	/**
	 * @param expRun
	 *            experiment run instance
	 */
	public VaryCardinalityScenario(ExperimentRun expRun) {
		super(expRun);
		planToExecutionTimeMap = new HashMap<Long, Long>();
	}

	/**
	 * Populate the variable table(s) for use in retrieving the optimal plan
	 * using the actual cardinality. For efficiency of the following steps,
	 * perhaps populate the variable table(s) at the maximum cardinality,
	 * storing these tables as template tables, and then partially clone the
	 * table(s) as the variable tables.
	 * 
	 * @param phase_number
	 * @param variableTables
	 *            The variable tables to be populated.
	 * @throws Exception
	 *             if something went wrong in this step.
	 */
	protected void stepA(int phase_number, Table[] variableTables)
			throws Exception {
	}

	/**
	 * Time the query plan execution. Used for timing the optimal plan.
	 * 
	 * @param sql
	 *            The query string.
	 * @param plan
	 *            The plan selected for the query.
	 * @param cardinality
	 *            The (variable) table cardinality at which the plan was
	 *            selected.
	 * @return The <code>QueryRunStat</code> instance containing the timing
	 *         information. By default, null is returned indicating no timing
	 *         data should be stored in the lab notebook.
	 */
	protected QueryRunStat stepB(int phaseNumber, String sql, PlanNode plan,
			long cardinality) throws Exception {
		return null;
	}

	/**
	 * <p>
	 * Change the table cardinality to the requested one. The cardinality is
	 * guaranteed to decrease over subsequent calls.
	 * </p>
	 * <p>
	 * Note that at the beginning, <code>requested_cardinality</code> will be
	 * equal to the table's maximum cardinality. So simply cloning the template
	 * table (which could contain the maximum cardinality) is an efficient
	 * approach. Subsequently, as the requested cardinality decreases, rows can
	 * be deleted from the variable table accordingly.
	 * </p>
	 * 
	 * @param requested_cardinality
	 *            Requested table cardinality.
	 * @return false indicating that no further work on this query should be
	 *         done, for example the requested_cardinality is less than the
	 *         actual cardinality.
	 */
	protected boolean stepC(int phaseNumber, Table[] variableTables,
			long requested_cardinality) throws Exception {
		return false;
	}

	/**
	 * Time the query plan execution. Used for timing the plans generated as the
	 * variable table cardinality decreases.
	 * 
	 * @param sql
	 *            The query string.
	 * @param plan
	 *            The plan selected for the query.
	 * @param cardinality
	 *            The (variable) table cardinality at which the plan was
	 *            selected.
	 * @return The <code>QueryRunStat</code> instance containing the timing
	 *         information. By default, null is returned indicating no timing
	 *         data should be stored in the lab notebook.
	 */
	protected QueryRunStat stepD(int phaseNumber, String sql, PlanNode plan,
			long cardinality) throws Exception {
		return null;
	}

	/**
	 * Get the number of phases of the scenario.
	 * 
	 * @return the number of scenarios.
	 */
	// check the actual scenario instance to see its value. In first round of
	// scenarios, it is =1.
	protected abstract int getNumOfPhases();

	/**
	 * @see azdblab.plugins.scenario.Scenario#executeSpecificExperiment()
	 */
	protected final boolean executeSpecificExperiment() throws Exception {
		initializeLabNotebookContent();
		initializeExperimentTables();
		// Looping on the phases.
		for (int phase = 1; phase <= getNumOfPhases(); phase++) {

			stepA(phase, myVariableTables);

			Vector<Query> experimentRunQueries = exp_run_.getExperimentRunQueries();
			// Run exp_run = dbController.getUser(userName)
			// .getNotebook(notebookName)
			// .getExperiment(experimentName)
			// .getRun(startTime);
			// Looping on the queries
			for (int i = 0; i < experimentRunQueries.size(); i++) {
				Query expRunQuery = experimentRunQueries.get(i);
				Element queryResult = null;

				// if(exp_run.getQuery(expRunQuery.iQueryNumber).queryHasResult())
				// {
				if (expRunQuery.queryHasResult(phase)) {
					// dbController.queryHasResult(
					// userName, notebookName, experimentName, startTime,
					// phase, expRunQuery.iQueryNumber,
					// expRunQuery.strQuerySQL)){
					// get the result from the database
					// queryResult =
					// exp_run.getQuery(expRunQuery.iQueryNumber).getQueryResult();
					queryResult = expRunQuery
							.getQueryResult(new int[] { phase });
					// queryResult = dbController.getQueryResult(
					// userName, notebookName, experimentName, startTime,
					// new int[] {phase}, expRunQuery.iQueryNumber);
					if (Main.verbose) {
						Main._logger.outputLog("Retrieving Result for Query #"
								+ expRunQuery.iQueryNumber + ": "
								+ expRunQuery.strQuerySQL);
					}
					queryResult = (Element) myResultXML.importNode(queryResult,
							true);
				} else {
					// Query hasn't yet been analyzed.
					if (checkToBePaused()) {
						Main._logger.outputLog("paused!!!");
						return false; // Stop, not finished yet
					}
					// starts to run new query.
					queryResult = myResultXML.createElement("queryResult");
					queryResult.setAttribute("sql", expRunQuery.strQuerySQL);
					recordRunProgress(Math.min((int) ((double) (i + 1)
							/ (double) experimentRunQueries.size() * 100), 99),
							"Analyzing Query # " + i);
					if (Main.verbose) {
						Main._logger.outputLog("Analyzing Query #"
								+ expRunQuery.iQueryNumber + ": "
								+ expRunQuery.strQuerySQL);
					}
					// Study the query.
					analyzeQuery(phase, queryResult, expRunQuery.iQueryNumber,
							expRunQuery.strQuerySQL, experimentRun
									.getSearchMethod(), experimentRun
									.getSearchGranularity());
					File queryResultFile = File.createTempFile("queryResult",
							".xml", new File(Constants.DIRECTORY_TEMP));
					queryResultFile.deleteOnExit();
					XMLHelper.writeXMLToOutputStream(new FileOutputStream(
							queryResultFile), queryResult);
					Main._logger.outputLog("before validate query result");
					XMLHelper.validate(
							// (getClass().getClassLoader().getResourceAsStream(
							new FileInputStream(new File(
									Constants.CHOSEN_QUERY_RESULT_SCHEMA)),
							queryResultFile);
					Main._logger.outputLog("before insert query result");
					/*
					 * dbController.getUser(userName) .getNotebook(notebookName)
					 * .getExperiment(experimentName) .getRun(startTime)
					 * .getQuery
					 * (expRunQuery.iQueryNumber).insertQueryResult(phase, new
					 * FileInputStream(queryResultFile));
					 */
					expRunQuery.insertQueryResult(phase, new FileInputStream(
							queryResultFile));
					// dbController.insertQueryResult(
					// userName, notebookName, experimentName, startTime,
					// phase, expRunQuery.iQueryNumber, new
					// FileInputStream(queryResultFile));
				}
				testResult.appendChild(queryResult);
				Main._logger.outputLog("executing a query");
			}

		}
		return true;
	}

	/**
	 * Studying a query.
	 * 
	 * @param queryResult
	 *            The XML element to hold the study result.
	 * @param queryNumber
	 *            The number of the query in the experiment.
	 * @param sql
	 *            The SQL query string.
	 * @param method
	 *            Method for constructing candidate cardinality
	 * @param granularity
	 *            Granularity for changing cardinality.
	 * @throws Exception
	 */
	private void analyzeQuery(int phaseNumber, Element queryResult,
			int queryNumber, String sql, String method, long granularity)
			throws Exception {
		vecQueryPlans = new Vector<Long>();
		planToExecutionTimeMap.clear();
		
		// 1M plan at start
		PlanNode oneMPlan = null;
		if (phaseNumber == 1) {
			for (int i = 0; i < myFixedTables.length; i++) {
				Table curr_table = myFixedTables[i];
				experimentSubject.updateTableStatistics(
						curr_table.table_name_with_prefix,
						curr_table.actual_card, true);
			}

			//////////////////////////////////////////////////////////////////////////////////////////////////////////
			// first pass
			//////////////////////////////////////////////////////////////////////////////////////////////////////////
			// deleting top 10k rows 100 times
			for (int i = 0; i < myVariableTables.length; i++) {
				Table curr_table = myVariableTables[i];
				long min = curr_table.hy_min_card; 
				long max = curr_table.hy_max_card;
				if (Main.verbose) {
					Main._logger.outputLog("<1M Plan> Starting deleting top10K rows at Cardinality = " + max + " (min: " + min + ")");
				}
				// TreeSet<Long> executed_plans = new TreeSet<Long>();
				Vector<Long> vecCardinalities = generateCandidateCardinalities(method, min, max, granularity);
				long current_cardinality = -1;
				for (i = 0; i < vecCardinalities.size(); i++) {
					// search the entire space, very slow
					if (Main.verbose) {
						System.out.print(".");
					}
					current_cardinality = vecCardinalities.get(i);
					boolean should_continue = stepC(phaseNumber, myVariableTables, current_cardinality);
					if (!should_continue) {
						break;
					}
				} // end of for loop for each candidate cardinality
				if (Main.verbose) {
					Main._logger.outputLog("\n<1M Plan>Ending deleting top10K rows at Cardinality = " + current_cardinality);
				}
			}
			Main._logger.outputLog("<First Pass>#### print table rows and pages ###");
			experimentSubject.printTableStat(myVariableTables[0].table_name_with_prefix);
			
//			for (int i = 0; i < myVariableTables.length; i++) {
//				Table curr_table = myVariableTables[i];
//				// first copy clone table to variable table
//				// ft_HT1 is supposed to be deleted, not "clone_max" table)
//		    	experimentSubject.cloneTable(curr_table.table_name_with_prefix, "clone_max_" + curr_table.table_name_with_prefix); 
//		        // yksuh has added the below function to make it consistent with stepC
//				experimentSubject.updateTableCardinality(curr_table.table_name_with_prefix, curr_table.actual_card, curr_table.hy_max_card);
//		        experimentSubject.updateTableStatistics(curr_table.table_name_with_prefix,curr_table.actual_card, true);
//			}

			planToPlanNumberMap = new HashMap<Long, Integer>();
			// This is the optimal run according to the optimizer
			PlanNode temp_plan = experimentSubject.getQueryPlan(sql);
			oneMPlan = temp_plan;
			
			// Step B of the scenario.
			QueryRunStat opt_qs = stepB(phaseNumber, sql, temp_plan, myVariableTables[0].actual_card);

			// put in hash table for quicker search later
			vecQueryPlans.add(temp_plan.myHashCode());
			planToPlanNumberMap.put(temp_plan.myHashCode(), new Integer(0));
			// Create a change point for the optimal plan.
			QueryRun optimalQueryRun = new QueryRun(myVariableTables.length);

			optimalQueryRun.plan = temp_plan;
			
			optimalQueryRun.myQueryRunTables[0].max_val = myVariableTables[0].actual_card;
			optimalQueryRun.myQueryRunTables[0].min_val = myVariableTables[0].actual_card;
			optimalQueryRun.myQueryRunTables[0].table_name = myVariableTables[0].table_name;
			/************************************
			optimalQueryRun.isOptimal = true;
			
			Vector<QueryRun> optimalPlanVector = new Vector<QueryRun>();
			optimalPlanVector.add(optimalQueryRun);
			if (opt_qs != null) {
				optimalQueryRun.exec_time = opt_qs.getQueryTime();
			}
			*************************************/
			
			/************************************************************************
			 * Young's note: 
			 * there is no place to use 'optimalPlanVector', and thus, I deleted it.
			 * Also, I assigned phaseNumber to optimalQueryRun.phaseNumber although
			 * it's not needed. 
			 * **********************************************************************/
			if (opt_qs != null) {
				optimalQueryRun.exec_time = opt_qs.getQueryTime();
			}
			optimalQueryRun.phaseNumber = phaseNumber;			
			/*****************************************************************/
			
			// recording the optimal plans results in xml and dbms
			/**********************************************************************************************************************
			Element optimalQueryRunElement = recordQueryRun(optimalQueryRun, queryNumber, Constants.OPTIMAL_CHANGE_POINT_NUMBER);
			************************************************************************************************************************/
			/************************************************************************
			 * Young's note: 
			 * Since 'optimalQueryRun' is the change point gotten at 1M, 
			 * I pass 'true' flag to 'recordQueryRun()'. 
			 * **********************************************************************/
			Element optimalQueryRunElement = recordQueryRun(optimalQueryRun, queryNumber, Constants.OPTIMAL_CHANGE_POINT_NUMBER, true);
			/*****************************************************************/
			queryResult.appendChild(optimalQueryRunElement);
		}
		Main._logger.outputLog("continue in analyze query");

		// change_points found by exhaustive search and optimal plan
		// find the plan change points while changing the cardinality
		Main._logger.outputLog("before find query runs");
		Vector<QueryRun> query_runs = findQueryRuns(phaseNumber, sql,
				queryNumber, method, granularity);
		
		Main._logger.outputLog("<< 2) print table rows and pages after finding query runs >> ");
		experimentSubject.printTableStat(myVariableTables[0].table_name_with_prefix);
		
		executeQueryRuns(phaseNumber, sql, query_runs);
		Main._logger.outputLog("after find query runs");
		// adding the change point results to the xml and databasenew_plan_code
		
		for (int i = 0; i < query_runs.size(); i++) {
			QueryRun current_point = (QueryRun) query_runs.get(i);
			
			/*****************************************************************
			Element queryRunElement = recordQueryRun(current_point, queryNumber, i);
			/*****************************************************************/
			/************************************************************************
			 * Young's note: 
			 * Since 'current_point' is a change point gotten at a cardinality, 
			 * I pass 'false' flag to 'recordQueryRun()'. 
			 * **********************************************************************/
			Element queryRunElement = recordQueryRun(current_point, queryNumber, i, false);
			queryResult.appendChild(queryRunElement);
			current_point.plan.myHashCode();
		}
		Main._logger.outputLog("done recording all query runs");
		if (phaseNumber == 1) {
			TreeSet<Long> subopt_plan_set = new TreeSet<Long>();
			for (int i = 0; i < query_runs.size(); i++) {
				QueryRun current_point = (QueryRun) query_runs.get(i);
				subopt_plan_set.add(current_point.plan.myHashCode());
			}
			mapQueryToSubOptPlan.put(queryNumber, subopt_plan_set);
		}
	}

	/***
	 * The purpose of findQueryRuns is to find the minimum cardinalities for
	 * each plan Also, to allow comparison to closest plan A below it rather
	 * than Plan A at 1million This allows us to range cardinalities all the way
	 * down to 1. It also allows us to be less conservative about which plans
	 * are suboptimal If we run the plans at the minimum cardinality, it is
	 * closer to the cardinality for closest plan A than at max
	 * 
	 * Locates query runs in the specified range.
	 * 
	 * @param phaseNumber
	 *            : phaseNumber. Currently 1
	 * @param sql
	 *            The SQL for the query that is being analyzed.
	 * @param queryNumber
	 *            The query number of the query being analyzed.
	 * @param method
	 *            method used for determining the test cardinalities.
	 * @param granularity
	 *            The granularity of the search.
	 * @return A vector of query runs.
	 * @throws Exception
	 *             If something fails.
	 */
	private Vector<QueryRun> findQueryRuns(int phaseNumber, String sql,
			int queryNumber, String method, long granularity) throws Exception {
		set_new_plans_ = new TreeSet<Long>();
		Vector<QueryRun> resultQueryRun = new Vector<QueryRun>();
		int planCount = 1;
		Table[] variable_table = myVariableTables;
//		QueryRun curr_queryrun;
		long min = variable_table[0].hy_min_card; // hy_min_card and hy_max_card
												  // come from XML file
		long max = variable_table[0].hy_max_card;
		if (Main.verbose) {
			Main._logger.outputLog("Starting Change Point Discovery at Cardinality = " + max + " (min: " + min + ")");
		}
		// TreeSet<Long> executed_plans = new TreeSet<Long>();
		Vector<Long> vecCardinalities = generateCandidateCardinalities(method, min, max, granularity);
		long current_cardinality = -1;
		PlanNode prev_node = null;
		for (int i = 0; i < vecCardinalities.size(); i++) {
			// search the entire space, very slow
			if (Main.verbose) {
				System.out.print(".");
			}
			current_cardinality = vecCardinalities.get(i);
			QueryRun curr_queryrun = new QueryRun(1); // one change point table
			
			for (int j = 0; j < variable_table.length; j++) { // for each
															  // variable
															  // table
				curr_queryrun.myQueryRunTables[j].min_val = current_cardinality;
				curr_queryrun.myQueryRunTables[j].max_val = current_cardinality;
				curr_queryrun.myQueryRunTables[j].table_name = myVariableTables[j].table_name;
				/**********************************************************************/	
				curr_queryrun.phaseNumber = phaseNumber;
				/***********************************************************************/
			}
			
			boolean should_continue = stepC(phaseNumber, myVariableTables, current_cardinality);
			if (!should_continue) {
				break;
			}

			// get a plan at a certain cardinality, 'c'
			PlanNode new_plan_node = experimentSubject.getQueryPlan(sql);
			if (new_plan_node == null) {
				continue;
			}
			long new_plan_code = new_plan_node.myHashCode();
			set_new_plans_.add(new_plan_code);
			
			
			/**************************************************************************************************
			// extract the query plan from the DBMS for this cardinality
			if (vecQueryPlans.size() == 1
					|| (vecQueryPlans.get(vecQueryPlans.size() - 1).longValue()) != new_plan_code) {
				// this plan is not equal to the last plan, so this is a change point
				int planNumber = vecQueryPlans.indexOf(new_plan_code);
				if (planNumber == -1) {
					// this is a new plan, never before seen
					planToPlanNumberMap.put(new_plan_code, new Integer(planCount));
					curr_queryrun.planNumber = planCount++;
				} else {
					curr_queryrun.planNumber = ((Integer) planToPlanNumberMap.get(new_plan_code)).intValue();
				}
				if (Main.verbose) {
					Main._logger.outputLog("\nFound change point (using Plan #"
							+ curr_queryrun.planNumber
							+ ") with Cardinality = " + current_cardinality);
				}
				curr_queryrun.plan = new_plan_node;

				// Plan A
				if (planNumber == 0){
					Main._logger.outputLog("This plan is optimal .... :  " + curr_queryrun.planNumber + "/" + curr_queryrun.myQueryRunTables[0].max_val);
					curr_queryrun.isOptimal = true;
				}
				else{
					Main._logger.outputLog("This plan is non-optimal plan .... :  " + curr_queryrun.planNumber + "/" + curr_queryrun.myQueryRunTables[0].max_val);
					curr_queryrun.isOptimal = false;
				}
				vecQueryPlans.add(vecQueryPlans.size(), new_plan_code);
				resultQueryRun.add(resultQueryRun.size(), curr_queryrun);
			} // end of if vecQueryPlans.size()==1 ....
			/**************************************************************************************************/
			
			/***********************************************************************************
			 * Young's note: 
			 * Below is the new adjacent scenario we discussed on Mar 2.
			 * *********************************************************************************/
			// extract the query plan from the DBMS for this cardinality
			// this plan is not equal to the last plan, so this is a change point
			if (vecQueryPlans.size() == 1
					|| (vecQueryPlans.get(vecQueryPlans.size() - 1).longValue()) != new_plan_code) {
				if(vecQueryPlans.size() > 1){
//					Main._logger.outputLog("<< 1) print table rows and pages after finding a change point >> ");
//					experimentSubject.printTableStat(myVariableTables[0].table_name_with_prefix);
					
					// create a query run for lower cardinality 
					QueryRun lower_queryrun = new QueryRun(1);
					for (int j = 0; j < variable_table.length; j++) { // for each
						  											  // variable
						  											  // table
						lower_queryrun.myQueryRunTables[j].min_val = current_cardinality+granularity;
						lower_queryrun.myQueryRunTables[j].max_val = current_cardinality+granularity;
						lower_queryrun.myQueryRunTables[j].table_name = myVariableTables[j].table_name;
						/**********************************************************************/	
						lower_queryrun.phaseNumber = phaseNumber;
						/***********************************************************************/
					}
					QueryRun upper_queryrun = resultQueryRun.get(resultQueryRun.size()-1);
					
					PlanNode lower_plan = prev_node;
					if(lower_plan.myHashCode() != upper_queryrun.plan.myHashCode()){
						if (Main.verbose) {
							throw new Exception(
								"findQueryRuns: The plan found at lower bound is different from one found at upper bound" +
							   "lower_plan: " + lower_plan.myHashCode() + ", upper_plan: " + upper_queryrun.plan.myHashCode());
						}
					}
					lower_queryrun.plan = lower_plan;
					lower_queryrun.planNumber = upper_queryrun.planNumber;
					
					if (Main.verbose) {
						Main._logger.outputLog("\nCreate a lower query run (using Plan #"
								+ lower_queryrun.planNumber + "/<" + lower_queryrun.plan.myHashCode() + ">"
								+ ") with Cardinality = " + lower_queryrun.myQueryRunTables[0].max_val);
					}

					// 1.01M or 1.99M are covered by the below routine
					if(upper_queryrun.myQueryRunTables[0].max_val != lower_queryrun.myQueryRunTables[0].max_val){
						resultQueryRun.add(resultQueryRun.size(), lower_queryrun);
					}
//					vecQueryPlans.add(vecQueryPlans.size(), lower_plan.myHashCode());
					// add lower bound query run
//					resultQueryRun.add(resultQueryRun.size(), lower_queryrun);
				}
				
				// create a query run for upper cardinality 
				int planNumber = vecQueryPlans.indexOf(new_plan_code);
				if (planNumber == -1) {
					// this is a new plan, never before seen
					planToPlanNumberMap.put(new_plan_code, new Integer(planCount));
					curr_queryrun.planNumber = planCount++;
				} else {
					curr_queryrun.planNumber = ((Integer) planToPlanNumberMap.get(new_plan_code)).intValue();
				}
				if (Main.verbose) {
					Main._logger.outputLog("\nFound change point (using Plan #"
							+ curr_queryrun.planNumber + "/<" + new_plan_code + ">"
							+ ") with Cardinality = " + current_cardinality);
				}
				curr_queryrun.plan = new_plan_node;
				vecQueryPlans.add(vecQueryPlans.size(), new_plan_code);
				resultQueryRun.add(resultQueryRun.size(), curr_queryrun);
			} // end of if vecQueryPlans.size()==1 ...
			prev_node = new_plan_node;
		} // end of for loop for each candidate cardinality
		
		if (Main.verbose) {
			Main._logger.outputLog("\nEnding Query Run Discovery at Cardinality = " + current_cardinality);
		}
		
		// get plan at 1M again
Main._logger.outputLog("<<< timing 1M plan again at 1M >>>");
Main._logger.outputLog("<< print table rows and pages before timing 1M plan again at 1M >> ");
experimentSubject.printTableStat(myVariableTables[0].table_name_with_prefix);
		// time the query 
		QueryRun oneMPQueryRunAtEnd = new QueryRun(myVariableTables.length);
		// get 1M plan
		PlanNode lastOneMP = experimentSubject.getQueryPlan(sql);
		long last_plan_code = lastOneMP.myHashCode();
		set_new_plans_.add(last_plan_code);
		int planNumber = vecQueryPlans.indexOf(last_plan_code);
		if (planNumber == -1) {
			// this is a new plan, never before seen
			planToPlanNumberMap.put(last_plan_code, new Integer(planCount));
			oneMPQueryRunAtEnd.planNumber = planCount++;
		} else {
			oneMPQueryRunAtEnd.planNumber = ((Integer) planToPlanNumberMap.get(last_plan_code)).intValue();
		}
		oneMPQueryRunAtEnd.plan = lastOneMP;
		oneMPQueryRunAtEnd.myQueryRunTables[0].max_val = myVariableTables[0].actual_card;
		oneMPQueryRunAtEnd.myQueryRunTables[0].min_val = myVariableTables[0].actual_card;
		oneMPQueryRunAtEnd.myQueryRunTables[0].table_name = myVariableTables[0].table_name;
		oneMPQueryRunAtEnd.phaseNumber = phaseNumber;	
		// to avoid duplicate query runs at 1M 
		QueryRun last_queryrun = resultQueryRun.get(resultQueryRun.size()-1);
		if(last_queryrun.myQueryRunTables[0].max_val != oneMPQueryRunAtEnd.myQueryRunTables[0].max_val){
			vecQueryPlans.add(vecQueryPlans.size(), last_plan_code);
			resultQueryRun.add(resultQueryRun.size(), oneMPQueryRunAtEnd);
		}
//		vecQueryPlans.add(vecQueryPlans.size(), last_plan_code);
//		resultQueryRun.add(resultQueryRun.size(), oneMPQueryRunAtEnd);
		
		Iterator<Long> iter_new_plans = set_new_plans_.iterator();
		Main._logger.outputLog("All Found Plans");
		while (iter_new_plans.hasNext()) {
			Main._logger.outputLog(iter_new_plans.next());
		}
		Main._logger.outputLog("End of All Found Plans");

		/***********************************************************************************
		 * Young's note: 
		 * Below is what we determined to take out. It used to update adjacent cardinality 
		 * the current query run by taking advantage of the next query run's cardinality
		 * *********************************************************************************/
		/*********************************************************************************************************
		// For each queryRun
		// For all the change points, we look for the closest "optimal" plan that has cardinality smaller than 
		// the current change point.
		for (int i = 0; i < resultQueryRun.size() - 1; ++i) {
//		for (int i = 0; i < resultQueryRun.size(); ++i) {		
			QueryRun current_qr = resultQueryRun.get(i);

			// This is plan A, we want to keep cardinality at change point.
			if (current_qr.isOptimal) {
				Main._logger.outputLog("For optimal plan we don't have to update adjacent cardinality .... :  " + current_qr.planNumber + "/" + current_qr.myQueryRunTables[0].max_val);
			} else {
				QueryRun next_qr = resultQueryRun.get(i + 1);
				current_qr.myQueryRunTables[0].max_val = next_qr.myQueryRunTables[0].max_val
						+ granularity;
				current_qr.myQueryRunTables[0].min_val = next_qr.myQueryRunTables[0].min_val
						+ granularity;
				
				// to take care of the case where the last plan is A
				if (next_qr.isOptimal) {
				}
				
//				QueryRun next_qr = resultQueryRun.get(i + 1);
//				if (next_qr.isOptimal) {
//					next_qr.myQueryRunTables[0].max_val = current_qr.myQueryRunTables[0].max_val
//					+ granularity;
//					next_qr.myQueryRunTables[0].min_val = current_qr.myQueryRunTables[0].min_val
//					+ granularity;
//				}
			}
		}
		
		/**************************************************************************************************/
		// remove plans that are below the lowest Plan A.
		// Since A always has to be to the left of the plan to check for
		// suboptimality
		// for (int i = last_plan_A_id - 1; i >= 0; --i) {
		// resultQueryRun.remove(i);
		// }
		Main._logger.outputLog("Remaining query runs:");
		for (int i = 0; i < resultQueryRun.size(); ++i) {
			System.out.print(resultQueryRun.get(i).planNumber);
		}
		Main._logger.outputLog();
		// print out a sequence of query run numbers of resultQuerun for sanity check.
		return resultQueryRun;
	}

	/**
	 * 
	 * @param phaseNumber
	 *            : phaseNumber. Currently 1
	 * @param sql
	 *            The SQL for the query that is being analyzed.
	 * @param resultQueryRun
	 *            : The vector of QueryRuns, i.e., the adjacent change points
	 * @throws Exception
	 *             If something fails.
	 */

	private void executeQueryRuns(int phaseNumber, String sql,
			Vector<QueryRun> resultQueryRun) throws Exception {
		// set_new_plans_ = new TreeSet<Long>();
		if (Main.verbose) {
			Main._logger.outputLog("Starting execution of Steps C and D for all adjacent plans");
		}
		// Run Steps C and D for each plan
		QueryRun curr_queryrun;
		curr_queryrun = new QueryRun(1);
		for (int i = 0; i < resultQueryRun.size(); ++i) {
			curr_queryrun = resultQueryRun.elementAt(i);
			
			boolean should_continue = stepC(phaseNumber, myVariableTables, curr_queryrun.myQueryRunTables[0].max_val);
			if (!should_continue) {
				Main._logger.outputLog("Should break!");
				break;
			}
			
//Main._logger.outputLog("<< 3) print table rows and pages before executing a query run >> ");
//experimentSubject.printTableStat(myVariableTables[0].table_name_with_prefix);
			
			PlanNode new_plan_node = experimentSubject.getQueryPlan(sql);
			Main._logger.outputLog("get plan for query: " + sql);
			QueryRunStat opt_qs = stepD(phaseNumber, sql, new_plan_node,
					curr_queryrun.myQueryRunTables[0].max_val);
			if (opt_qs != null) {
				curr_queryrun.exec_time = opt_qs.getQueryTime();
			}
		}
	}

	
//	/**
//	 * Records a change point in the lab notebook. The result is also recorded
//	 * in the XML result.
//	 * 
//	 * @param current_point
//	 *            The current change point.
//	 * @param queryNumber
//	 *            The query number that this change point is associated with.
//	 * @param cp_number
//	 *            The change point number for this change point.
//	 * @param one1MPlan
//	 *            denotes whether 'current_point' is a change point at 1M or not
//	 * @return The element that stores the result of this change point.
//	 */
//	private Element recordQueryRun(QueryRun current_point, 
//								   int queryNumber,
//								   int cp_number, 
//								   boolean one1MPlan) {
//								
//		Element query_run;
//		if (one1MPlan) {
//			query_run = myResultXML.createElement("optimalPlan");
//		}else{
//			query_run = myResultXML.createElement("queryRun");
//		}
//		Query temp_query = exp_run_.getQuery(queryNumber);
//		query_run.setAttribute("executionTime", current_point.exec_time + "");
//		query_run.setAttribute("units", "milli seconds");
//		query_run.setAttribute("planNumber", current_point.planNumber + "");
//		query_run.setAttribute("phaseNumber", current_point.phaseNumber + "");
//		
//Main._logger.outputLog("****** (queryExecutionNumber, cardinality)*************");
//		for (int i = 0; i < current_point.myQueryRunTables.length; i++) {
//Main._logger.outputLog("("+cp_number+", "+ current_point.myQueryRunTables[i].max_val +")");
//			int queryrun_id = temp_query.insertQueryRun(
//					current_point.phaseNumber, 
//					queryNumber, 
//					cp_number,
//					current_point.myQueryRunTables[i].max_val,
//					current_point.getResultCardinality(),
//					current_point.exec_time);
//			
//			if (queryrun_id < 0) {
//				System.err.println("queryrun id cannot be negative!");
//				continue;
//			}
//			
//			// dbController.insertQueryRun(
//			// userName, notebookName, experimentName, startTime,
//			// current_point.phaseNumber, queryNumber, cp_number,
//			// current_point.myQueryRunTables[i].max_val,
//			// current_point.exec_time);
//			if (current_point.phaseNumber != 2) {
//				Main._logger.outputLog("before inserting the plan of a change point ... ");
//				temp_query.insertPlan(queryNumber,
//									  cp_number, 
//									  queryrun_id,
//									  current_point.plan);
//				Main._logger.outputLog("done with inserting the plan of a change point ... ");
//				// dbController.insertPlan(
//				// userName, notebookName, experimentName, startTime,
//				// queryNumber, cp_number, current_point.plan);
//			}
//			
//			Element table = myResultXML.createElement("table");
//			table.setAttribute("name",
//					current_point.myQueryRunTables[i].table_name);
//			table.setAttribute("cardinality",
//					current_point.myQueryRunTables[i].max_val + "");
//			query_run.appendChild(table);
//		}
//Main._logger.outputLog("*************************************************");
//		
//		
//		Main._logger.outputLog("return query_run");
//		return query_run;
//	}

	/**
	 * Records a change point in the lab notebook. The result is also recorded
	 * in the XML result.
	 * 
	 * @param current_point
	 *            The current change point.
	 * @param queryNumber
	 *            The query number that this change point is associated with.
	 * @param cp_number
	 *            The change point number for this change point.
	 * 
	 * Young: the below new parameter, 'one1MPlan', indicates whether the give 'current_point' is 
	 * 		  a change point at 1M or not
	 * @param one1MPlan
	 *            denotes whether 'current_point' is a change point at 1M or not
	 * @return The element that stores the result of this change point.
	 */
	/*******************************************************
	private Element recordQueryRun(QueryRun current_point, 
								   int queryNumber,
								   int cp_number) {
    *********************************************************/
	private Element recordQueryRun(QueryRun current_point, 
								   int queryNumber,
								   int cp_number, 
								   boolean one1MPlan) {
		Element query_run = myResultXML.createElement("queryRun");
		
		/*********************************************************
		if (current_point.isOptimal) {
			query_run = myResultXML.createElement("optimalPlan");
		}
		**********************************************************/
		if (one1MPlan) {
			query_run = myResultXML.createElement("optimalPlan");
		}else{
			query_run = myResultXML.createElement("queryRun");
		}
			
		Query temp_query = exp_run_.getQuery(queryNumber);
		query_run.setAttribute("executionTime", current_point.exec_time + "");
		query_run.setAttribute("units", "milli seconds");
		query_run.setAttribute("planNumber", current_point.planNumber + "");
		query_run.setAttribute("phaseNumber", current_point.phaseNumber + "");
		
Main._logger.outputLog("****** (queryExecutionNumber, cardinality)*************");
		for (int i = 0; i < current_point.myQueryRunTables.length; i++) {
Main._logger.outputLog("("+cp_number+", "+ current_point.myQueryRunTables[i].max_val +")");
			int queryrun_id = temp_query.insertQueryRun(
					current_point.phaseNumber, 
					queryNumber, 
					cp_number,
					current_point.myQueryRunTables[i].max_val,
					current_point.getResultCardinality(),
					current_point.exec_time);
			
			if (queryrun_id < 0) {
				System.err.println("queryrun id cannot be negative!");
				continue;
			}
			
			// dbController.insertQueryRun(
			// userName, notebookName, experimentName, startTime,
			// current_point.phaseNumber, queryNumber, cp_number,
			// current_point.myQueryRunTables[i].max_val,
			// current_point.exec_time);
			if (current_point.phaseNumber != 2) {
				Main._logger.outputLog("before inserting the plan of a change point ... ");
				long planID = temp_query.insertPlan(queryNumber,
												    cp_number, 
												    queryrun_id,
												    current_point.plan);
				Main._logger.outputLog("done with inserting the plan of a change point ... ");
				
				Main._logger.outputLog("before inserting query run stat... ");
				// insert query run stat
				temp_query.insertQueryRunStat(queryrun_id, planID, current_point.plan);
				Main._logger.outputLog("done with inserting query run stat ... ");
				// dbController.insertPlan(
				// userName, notebookName, experimentName, startTime,
				// queryNumber, cp_number, current_point.plan);
			}
			
			Element table = myResultXML.createElement("table");
			table.setAttribute("name",
					current_point.myQueryRunTables[i].table_name);
			table.setAttribute("cardinality",
					current_point.myQueryRunTables[i].max_val + "");
			query_run.appendChild(table);
		}
		Main._logger.outputLog("*************************************************");
		
		Main._logger.outputLog("return query_run");
		return query_run;
	}

	/**
	 * Measuring the running time of a query plan.
	 * <p>
	 * In the case that timing is needed, this should be implemented by calling
	 * <code>experimentSubject.timeQuery</code>. Otherwise, a
	 * <code>QueryStat</code> with 0 as running time, will be simply returned.
	 * 
	 * @param sql
	 *            The query to be executed
	 * @param plan
	 *            the plan to be used for executing the query
	 * @param cardinality
	 *            the cardinality at which the input plan was generated for the
	 *            input query.
	 * @return The <code>QueryStat</code> instance which contains the running
	 *         time.
	 */
	protected QueryRunStat timeQueryExecution(String sql, PlanNode plan, long cardinality) throws Exception {
		Main._logger.outputLog("Time out is : " + Constants.EXP_TIME_OUT);
		QueryRunStat result_queryrun_stat = experimentSubject.timeQuery(sql,
				plan, cardinality, Constants.EXP_TIME_OUT);
		return result_queryrun_stat;
	}

	/**
	 * Generating the entire search space of the candidate cardinalities.
	 * 
	 * @param method
	 *            There are two methods, linear and exponential, for changing
	 *            the table cardinality.
	 * @param min
	 *            Minimum cardinality.
	 * @param max
	 *            Maximum cardinality.
	 * @param granularity
	 * @return
	 */
	private Vector<Long> generateCandidateCardinalities(String method,
			long min, long max, long granularity) {
		Vector<Long> vecCardinalities = new Vector<Long>();
		if (method.equals("linear")) {
			for (long i = max; i >= min; i = i - granularity) {
				vecCardinalities.add(i);
			}
		} else if (method.equals("exponential")) {
			int numInterval = 10;
			int maxExp = (int) (Math.log((double) max) / Math.log(2.0)) + 1;
			long currentMax = max;
			for (int i = maxExp; i > 0; i--) {
				long interval = currentMax - (long) Math.pow(2.0, (i - 1));
				long granExp = interval / numInterval;
				for (int j = 0; j < numInterval; j++) {
					long cardinality = currentMax - j * granExp;
					vecCardinalities.add(cardinality);
				}
				currentMax = (long) Math.pow(2.0, i - 1);
			}
		}
		return vecCardinalities;
	}

	/**
	 * Setting up the necessary variables for experiment.
	 * 
	 * @throws Exception
	 */
	private void initializeLabNotebookContent() throws Exception {
		Element tableSummary = null;
		mapQueryToSubOptPlan = new HashMap<Integer, TreeSet<Long>>();
		myFixedTables = experimentRun.getFixedTables();
		myVariableTables = experimentRun.getVariableTables();
		testResult = myResultXML.createElement("testResult");
		myResultXML.appendChild(testResult);
		SimpleDateFormat sdf = new SimpleDateFormat(Constants.TIMEFORMAT);
		/********************** INFORMATION SECTION ************************/
		Element log = myResultXML.createElement("log");
		testResult.appendChild(log);
		Element expTime = myResultXML.createElement("experimentTime");
		expTime.setAttribute("time", sdf.format(new Date(System
				.currentTimeMillis())));
		log.appendChild(expTime);
		Element dbversion = myResultXML.createElement("dbVersion");
		dbversion.setAttribute("version", experimentSubject.getDBVersion());
		log.appendChild(dbversion);
		Element azdblabVersion = myResultXML.createElement("azdblabVersion");
		azdblabVersion.setAttribute("version", Constants.AZDBLAB_VERSION);
		log.appendChild(azdblabVersion);
		Element experiment = myResultXML.createElement("experiment");
		log.appendChild(experiment);
		tableSummary = myResultXML.createElement("tableSummary");
		testResult.appendChild(tableSummary);
		// Building the XML for that summarizes the fixed tables.
		for (int i = 0; i < myFixedTables.length; i++) {
			Element table = myResultXML.createElement("table");
			String table_name = myFixedTables[i].table_name;
			table.setAttribute("name", table_name);
			table.setAttribute("seed", String.valueOf(myFixedTables[i]
					.getTableSeed()));
			table.setAttribute("actualCardinality", myDataDef
					.getTableCardinality(table_name)
					+ "");
			table.setAttribute("type", "fixed");
			tableSummary.appendChild(table);
		}
		// Building the XML for that summarizes the variable tables.
		for (int i = 0; i < myVariableTables.length; i++) {
			Element table = myResultXML.createElement("table");
			String table_name = myVariableTables[i].table_name;
			table.setAttribute("name", table_name);
			table.setAttribute("seed", String.valueOf(myVariableTables[i]
					.getTableSeed()));
			table.setAttribute("actualCardinality", myDataDef
					.getTableCardinality(table_name)
					+ "");
			table.setAttribute("type", "variable");
			tableSummary.appendChild(table);
		}
	}

	/**
	 * Creating and populating experiment tables.
	 * 
	 * @throws Exception
	 */
	private void initializeExperimentTables() throws Exception {

		if (myVariableTables.length != 1) {
			System.err
					.println("OneDimensionalExhaustiveAnalyzer: too many or too few variable "
							+ "tables: " + myVariableTables.length);
			System.exit(1);
		}

		// boolean isVariable = false;
		// Set up fixed tables
		for (int i = 0; i < myFixedTables.length; i++) {
			Table curr_table = myFixedTables[i];
			populateFixedTable(curr_table);
			// (int)((double)(i + 1) / (double)myVariableTables.length * 100) =
			// % completed
			recordRunProgress((int) ((double) (i + 1)
					/ (double) myVariableTables.length * 100),
					"Populating Fixed Tables");
		}
	}

	/**
	 * Populate the fixed tables.
	 * 
	 * @param table
	 *            The table to be populated.
	 */
	private void populateFixedTable(Table table) {
		RepeatableRandom rr = new RepeatableRandom(table.getTableSeed());
		rr.setMax(table.actual_card);
		// table.columns.length = number of columns in the table
		experimentSubject.populateTable(table.table_name_with_prefix,
				table.columns.length, table.actual_card, table.hy_max_card, rr,
				false);
		experimentSubject.updateTableStatistics(table.table_name_with_prefix,
				table.actual_card, true);
	}

	/**
	 * Result XML Component
	 */
	private Element testResult = null;

	/**
	 * The tables that are fixed for this experiment.
	 */
	private Table[] myFixedTables;

	/**
	 * The query plans that the analyzer has already seen.
	 */
	private Vector<Long> vecQueryPlans;

	/**
	 * The tables that are variable for this test.
	 */
	private Table[] myVariableTables;

	/**
	 * The map that associates query plans to query plan numbers.
	 */
	private HashMap<Long, Integer> planToPlanNumberMap;

	private HashMap<Integer, TreeSet<Long>> mapQueryToSubOptPlan;

	private TreeSet<Long> set_new_plans_;

	protected HashMap<Long, Long> planToExecutionTimeMap;
}
