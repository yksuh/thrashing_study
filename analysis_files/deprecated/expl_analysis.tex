%Chapter 8
\chapter{EXPLORATORY EVALUATION OF THE MODEL\label{chapter:explo_analysis}}

This chapter discusses our exploratory evaluation results of the model. 

\section{Environmental Challenges}\label{sec:challenges}

While conducting experiments to collect data for evaluating the model, 
we were faced with several practical challenges. 
In this section, we discuss what challenges we encountered and how to address them. 

% session duration
\subsection{Delayed Batchset Run Time}~\label{sec:delayed_batchset_run_time}
Referring to a previous paper~\cite{Jung2013}, 
two-minute batch run time plus one-minute think (stoppage) time as a minimum 
were initially set to execute each batch in a batchset.
Considering we have ten batches in each batchset, 
the batchset run was expected to end in about 90 minutes. 
However, the 90-minute batchset run time estimation took into little account on
several nontrivial other times, including 
%
1) table population time taking differently across \hbox{DBMSes}, 
%
2) longer labshelf access latency from a \hbox{DBMS}, running in virtual machine, 
%
3) slow disk drive flushing time in virtual machine, 
%
4) wait time for clients in session to be destroyed after batch run time, and 
%
5) idle times until resuming runs paused by runtime errors that occurred during experiments.

Due to these extra latencies, the actual batchset run took from ninety minutes up to a half day. 
As we planned to extend session time up to eight minutes for further operationalization, 
operationalizing session duration for the model put a big burden of meeting the timeline of this thesis work.
All things considered, we decided to remove this variable and its relevant interactions from the model.

To compensate for the removed session duration variable, 
we will execute each batch two times more. 
This change will bring the following two advantages. 
First, we can reinforce repeatability of our experiments. 
Collecting more samples allows us to increase the precison of the measured data.
Second, increasing more executions will serve as safety device. 
In case that the designed sanity checks, to be described soon, throw out dirty batch executions, 
the more executions we have, the more likely we are to retain the batch execution data, which will be used for further thrashing analysis.

This update applies to our confirmatory runs. 

% buffer space operationalization
\subsection{Difficult Buffer Space Operationalization}~\label{sec:buffer_space_oper}

Another environmental challenge is to make it hard to 
operationalize the buffer space variable in the model. 
Each \hbox{DBMS} has its own way of adjusting database buffer cache size. 
For instance, Teradata DBMS uses FSG cache~\cite{tdbc} for buffer space management. 
The size of FSG cache is determined as the ``percentage'' of the memory allocated to be FSG cache, 
out of free memory available in a system. 
Oracle and MySQL \hbox{DBMSes} use {\tt DB\_CACHE\_SIZE}~\cite{oraclebc} and {\tt innodb\_buffer\_pool\_size}~\cite{mysqlbc}, 
to set the size of buffer pool as a single ``value'', respectively.
\hbox{PostgreSQL} does not use a single value for the buffer cache size. 
Instead, a ``range'' for the buffer space allocation can be specified using the minimum and maximum size 
of shared memory segment ({\tt SHMMIN} and {\tt SHMMAX}) and 
the total amount of memory available (bytes or pages) ({\tt SHMALL})~\cite{pgdbc}. 
This implies that \hbox{PostgreSQL} will dynamically adjust the buffer space size along with current system circumstance.

Moreover, there were different constraints or additional information regarding buffer cache size. 
Oracle doesn't guarantee that the specified value stays the same. 
According to its document~\cite{oraclebc} , the value simply indicates the minimum. 
This means that the buffer pool size can dynamically change as Oracle DBMS treats workloads, 
as done in \hbox{PostgreSQL}. 
The varying size is exactly against our operationalization of the buffer pool space. 
\hbox{PostgreSQL} also had a constraint such that an allocation of more than 40\% of RAM to its buffer pool 
may not work better than a smaller amount. 
MySQL reserves 10\% more memory for managing buffers and control structures. 
Also, Teradata says that the percentage for FSG cache should be set depending on how much memory is free. 
The various configurations of these DBMSes made it harder to consistently operationalize the buffer space variable in the model. 
We, thus, decided not to keep the variable in the model.

Instead, we turned our attention to operationalizing physical memory. 

% buffer space operationalization
\subsection{Difficult Physical Memory Operationalization}~\label{sec:buffer_space_oper}

It would be very attractive to have the variable of the amount of physical memory in the model.
There are two reasons for this. 
One is that we might much more easily observe DBMS thrashing, by controlling available physical memory.
Actually, each connection made to that a DBMS consumes a certain amount of memory. 
PostgreSQL DBMS, for instance, creates a new {\tt postgres} process to serve a new connection. 
Oracle DBMS also creates a new {\tt oracle} process to take care of a new session. 
MySQL creates a new thread rather than process when a connection is made. 
The MySQL thread, although more lightweight than process, needs a certain amount of memory as long as it is still alive. 
If an operating system runs out of memory due to too many open DBMS sessions, 
then DBMS thrashing could readily occur. 
For this reason, we expected fairly high correlation between the amount of physical memory and DBMS thrashing, 
Investigating how strongly the physical memory variable can explain DBMS thrashing was very interesting to us.

Another reason is that the variable of the amount of physical memory has an advantage 
of specifically reflecting as an external factor system circumstance that can affect DBMS thrashing. 
Buffer space, allocated from a certain portion of physical memory, is used for efficient data management ``only'' for DBMSes. 
In that sense, the causal effect of buffer space on DBMS thrashing is internal.
On the other hand, physical memory is not only a source for buffer space, but also is a place for serving other processes 
running on the same machine running the DBMS processes.
It, therefore, could be interesting to see how much the rest of memory can externally participate in the thrashing phenomenon in DBMSes. 
We expected that having physical memory in the model would make our model more comprehensive.

However, operationalizing physical memory was a daunting task as well. 
We exerted to figure out how to control the amount of physical memory in BIOS or through operating system.
There, however, was no way of adjusting the size, 
except physically removing DRAMs from the slots on the main board of a machine, which was not feasible. 

% buffer space operationalization
There is one common aspect between buffer space and physical memory regarding DBMS thrashing.
Both indeed concern I/O, which is a very important causal factor.
To address this I/O influence on DBMS thrashing, 
we include the variable of primary key presence in the model. 

Using primary key enables DBMSes to use index instead of full scan. 
By involving primary keys, 
we can see how I/O can affect DBMS thrashing indirectly but through much easier operationalization.

By addressing these challenges and applying alternatives, 
we have revised our model, which will be discussed in the next section.

\section{Revised Model}\label{sec:revised_model}

\begin{figure}[htp!]
\centering
\includegraphics[scale=0.685]{./figures/new_causal_model.pdf}
\caption{The revised structural causal model of DBMS thrashing~\label{fig:revised_causal_model}}
\end{figure}

Figure~\ref{fig:revised_causal_model} shows the model we have revised through experiments used in our exploratory analysis. 
Compared to Figure~\ref{fig:causal_model}, 
we do not have the buffer space and session duration variables in the modified version. 
We also deleted the relevant interactions; that is, 
the two edges from buffer space to average transaction process time and MPL capability were removed, 
and in addition, deleted were the edges from session duration to average transaction processing time and 
from environment complexity to MPL capability. 
All other variables as well as the associated interactions remain the same as before. 

Instead, we now have the new variable of `primary key presence'.  
Accordingly, we have added two interactions in the model. 
One is to concern average transaction processing time, and 
the other is to moderate the interaction between transaction complexity and DBMS complexity.
Regarding these new interactions, the following hypotheses will be tested.

{\bf Hypothesis 12}: The presence of primary keys will significantly decrease ATP time, compared to their absence.

\noindent 
We hypothesize that the ATP time will be substantially reduced when primary keys are available on the tables that transactions refer to.
Without any indexes, DBMSes inevitably do full scans on the table(s) having objects requested by their transactions. 
In this case, significant I/O is accompanied, and it dominates the overall transactions' processing time. 
If primary keys are declared when tables are created, on the contrary,
most DBMSes typically create primary index for faster accesses to the table objects. 
When transactions refer to the objects in such tables having primary keys, 
the primary index will be exploited and significantly improve the DBMSes' transaction processing.

{\bf Hypothesis 13}: Primary keys will moderate the interaction between the DBMS complexity and transaction complexity; 
when primary keys are presented, as the percentages of rows from SELECT or UPDATE 
increase, the ATP time will not increase as much as the primary keys are unavailable.

\noindent 
Our hypothesis assumes that read-only or update-only transactions' processing time 
will be improved by the presence of primary keys although the percentage of objects accessed by the transactions 
increases. 
Primary keys will prevent DBMSes from doing full scans on the tables referenced by transactions. 
Considering I/O is the biggest component in transaction processing, 
DBMSes significantly benefit from primary index presented by primary keys. 
Even if more objects are accessed by transactions, the saved I/O through primary index 
will constrain a significant rise in processing delay.
Hence, we hypothesize that the primary key presence will negatively affects 
the interaction between percentage of row from SELECT or UPDATE and ATP time.

Besides, note that in the resource complexity construct, 
the variable of number of cores has been renamed to number of {\em processors}. 
Our experiment machine is equipped with quad-core, in which 
each core can run two processors thanks to hyper-threading technology.
Up to eight processors can be presented to Linux. 
By using processors, we can test the validity of our model with more rigorously than when using the number of cores.

\section{A Suite of Sanity Checks}\label{sec:sanity_checks}

%Our exploratory analysis is based on Hayes' book~\cite{Hayes13} about the introduction to mediation, moderation, and conditional process analysis.

We have come up with a variety of sanity checks, 
so hat we can conduct our exploratory analysis with clean data.
In this section, we present a suite of nine sanity checks devised along with each class. 

\paragraph{Terminology} 
We use the following terminologies in this section. 
A batch instance indicates a batch scheduled to run on a specific \hbox{DBMS}.
If we run a batch on four different \hbox{DBMSes}, then we will have four batch instances. 
Batch (instance) execution indicates that a batch instance gets executed on a \hbox{DBMS}.
If we run the same batch instance on a \hbox{DBMS} three times, then we will have three batch executions for that batch.
Similarly, a batchset instance represents a batchset scheduled to run on a specific \hbox{DBMS}, 
and if the batchset gets executed on a \hbox{DBMS}, this is called a batchset ``run'', rather than execution, 
to be distinguished from the batch execution case.

\paragraph{Designed Sanity Checks} 

Table~\ref{tab:ewc} lists the first class: the experiment-wide cases 
for which not a single violation should occur in a run: five such sanity checks. 
%
(1)~The number of missing batches indicates how many batch instances 
were not executed in a batchset instance, for whatever reason. 
In our data, there were no missed batches.
%
(2)~The inconsistent processor configuration violation checks whether 
the number of processors specified an experiment specification is inconsistent 
with the present processor configuration. 
%
We can figure out how many cores are currently enabled by examining the output from {\tt more /proc/cpuinfo}.
(3)~The number of insufficient iteration violations represents how many batch instances 
failed to repeat as many times as they were supposed to run.
In this thesis work, we decide to run each batch instance three times. 
If there's any batch instance having fewer than three iterations, 
we catch the batch instance as a violation. 
(4)~The number of other executor violations indicates how many batchset instances
were run together with another executor running on a different DBMS subject. 
We enforce that only one executor runs a batchset instance at a time. 
When an executor gets launched to run a batchset instance, 
if another executor is already running its batchset, then the launched executor must terminate immediately. 
We catch any batchset run failing to pass this sanity check.
(5)~The other DBMS process violation checks how 
many batchset instances ran together with other \hbox{DBMS} processes. 
We enforce that when a batchset instance gets run on a chosen \hbox{DBMS}, 
all the other \hbox{DBMSes}' processes should be deactivated except the processes 
of a chosen \hbox{DBMS}.

\begin{table}[t]
{
\centering
\begin{tabular}{|r|l|c|}
\hline 
1 & {\em Number of Missing Batches} & 0\\ 
\hline 
2 & {\em Number of Inconsistent Processor Configuration Violations} & 0\\ 
\hline 
3 & {\em Number of Insufficient Iterations} & 0 \\ 
\hline 
4 & {\em Number of Other Executor Violations} & 0 \\ 
\hline 
5 & {\em Number of Other DBMS Process Violations}  & 0\\
\hline
\end{tabular}
\caption{Experiment-wide sanity checks~\label{tab:ewc}}
}
\vspace{2ex}
{
\centering
\begin{tabular}{|r|l|c|}
\hline
1 & {\em Percentage of Zero TPS}  & ?\\
\hline
2 & {\em Percentage of Session Duration Violations} & ?\\
\hline
3 & {\em Percentage of Excessive ATP Time} & ?\\ \hline
\end{tabular}
\caption{Batch execution sanity checks~\label{tab:besc}}
}
%\end{table}
\vspace{2ex}
%\begin{table}
{
\centering
\begin{tabular}{|r|l|c|} \hline
1 & {\em Percentage of Transient Thrashing} & ?\\
\hline
\end{tabular}
\caption{Batchset sanity checks~\label{tab:bsec}}
}
\end{table}

%% Batch execution

The second class of sanity checks concerns batch (instance) executions; see Table~\ref{tab:besc}. 
Each of these four sanity checks could encounter a few isolated violations.
However, we expect the violation percentage to be low.  

(1)~The zero TPS violation identifies the percentage of batch executions where 
none of transactions were executed. 
If the number of these violations is excessive, then we could assume that experimental machines 
are not reliable. 
There is no violation \todo{Young: Check} observed in our data.

%
(2)~The session duration violation check identifies the percentage of batch executions 
that ran over or under the designated session duration. 
Fortunately, no \todo{Young: Check!}\ session duration violations were
observed across all batch executions in our data.

%
(3)~The excessive ATP time violation check indicates how many batch executions
revealed abnormally high ATP time. 
The threshold is defined as the average plus two standard deviations of the ATP time 
measured at a specific batch instance. 
Our data showed only \todo{Young: \#}\% violations as well. 
%

%% Q@Cs
The final class involves two checks over a batchset instance; 
see Table~\ref{tab:bsec}.
%
(2)~This sanity checks how many batchset instances experienced transient thrashing. 
We expect that the TPS at a thrashing point is most likely to be greater than the TPSes at higher MPLs.
In other words, once thrashing phase enters, we think that it's hard to come back up.
We observed no violations (\todo{Young: \#}\%).